{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bsPZQKgE3tX"
   },
   "source": [
    "## AIGCDetectBenchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZtRWDeMing8",
    "outputId": "5d83d40e-05ac-4bbe-a5b5-29ea56eaaca5"
   },
   "outputs": [],
   "source": [
    "!pip install ftfy -q\n",
    "!pip install natsort -q\n",
    "!pip install tensorboardX -q\n",
    "!pip install blobfile -q\n",
    "#!pip install mpi4py -q\n",
    "!apt-get install -y unzip -q\n",
    "!apt-get install -y zip -q\n",
    "!pip install imageio -q\n",
    "!pip install opencv-python -q\n",
    "!apt-get install -y libgl1-mesa-glx -q\n",
    "!pip install scikit-learn -q\n",
    "!pip install comet_ml -q\n",
    "!pip install regex -q\n",
    "!pip install scikit-image -q\n",
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4Tiyb4jExor",
    "outputId": "bdf03bf9-8943-4029-84d8-edecf00f1e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AIGCDetectBenchmark_ver2'...\n",
      "remote: Enumerating objects: 569, done.\u001b[K\n",
      "remote: Counting objects: 100% (569/569), done.\u001b[K\n",
      "remote: Compressing objects: 100% (361/361), done.\u001b[K\n",
      "remote: Total 569 (delta 263), reused 505 (delta 199), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (569/569), 7.44 MiB | 24.11 MiB/s, done.\n",
      "Resolving deltas: 100% (263/263), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vohoaidanh/AIGCDetectBenchmark_ver2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9HXSjhchADX",
    "outputId": "e7c10e63-1b0e-4c5f-8ea6-cdc24bd92a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/AIGCDetectBenchmark_ver2\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/AIGCDetectBenchmark_ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzAWmO8iNFZC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/workspace/AIGCDetectBenchmark_ver2/dataset', exist_ok = True)\n",
    "!unzip -q /workspace/RealFakeDB512s.zip -d /workspace/AIGCDetectBenchmark_ver2/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q /workspace/real_gen_dataset.zip -d /workspace/AIGCDetectBenchmark_ver2/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J17Cg4xCuKob",
    "outputId": "3d4dd873-0acf-4bfc-dddf-22977e314152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                 CropSize: 224                           \n",
      "               batch_size: 32                            \t[default: 64]\n",
      "                    beta1: 0.9                           \n",
      "                blur_prob: 0.1                           \n",
      "                 blur_sig: 0.0,3.0                       \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                  classes: ['airplane', 'bird', 'bicycle', 'boat', 'bottle', 'bus', 'car', 'cat', 'cow', 'chair', 'diningtable', 'dog', 'person', 'pottedplant', 'motorbike', 'tvmonitor', 'train', 'sheep', 'sofa', 'horse']\t[default: airplane,bird,bicycle,boat,bottle,bus,car,cat,cow,chair,diningtable,dog,person,pottedplant,motorbike,tvmonitor,train,sheep,sofa,horse]\n",
      "                    comet: True                          \t[default: False]\n",
      "           continue_train: False                         \n",
      "                 data_aug: False                         \n",
      "                 dataroot: /workspace/AIGCDetectBenchmark_ver2/dataset/RealFakeDB512s\t[default: /hotdata/share/AIGCDetect]\n",
      "                dataroot2: None                          \n",
      "            detect_method: CNNSpot_CAM                   \t[default: CNNSpot]\n",
      "          earlystop_epoch: 5                             \n",
      "              epoch_count: 1                             \n",
      "             fix_backbone: False                         \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                    isVal: False                         \t[default: None]\n",
      "               jpg_method: cv2,pil                       \n",
      "                 jpg_prob: 0.1                           \n",
      "                 jpg_qual: 30,100                        \n",
      "               last_epoch: -1                            \n",
      "                 loadSize: 256                           \n",
      "                loss_freq: 100                           \t[default: 400]\n",
      "                       lr: 0.0001                        \n",
      "           method_combine: None                          \n",
      "                     mode: binary                        \n",
      "       model_path_trained: /workspace/AIGCDetectBenchmark_ver2/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth\t[default: ./weights/classifier/CNNSpot.pth]\n",
      "                     name: 240508_CNNSpot_CAM            \t[default: experiment_name]\n",
      "                new_optim: False                         \n",
      "                    niter: 1000                          \n",
      "                  no_crop: False                         \n",
      "                  no_flip: False                         \n",
      "                no_resize: False                         \n",
      "              num_threads: 4                             \n",
      "                    optim: adam                          \n",
      "              results_dir: ./results/CNNSpot_CAM         \t[default: None]\n",
      "                rz_interp: bilinear                      \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 2000                          \n",
      "              train_split: train                         \n",
      "                val_split: val                           \n",
      "             weight_decay: 0.0                           \n",
      "----------------- End -------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/danhvohoai2-gmail-com/ai-generated-image-detection/9ae021bee03c4c57888d8809bb8d84b0\u001b[0m\n",
      "\n",
      "#training images = 625\n",
      "Train loss: 0.4618922472000122 at step: 100\n",
      "Train loss: 0.6537826061248779 at step: 400\n",
      "Train loss: 0.33009660243988037 at step: 500\n",
      "Train loss: 0.8701145648956299 at step: 600\n",
      "saving the model at the end of epoch 0, iters 625\n",
      "(Val @ epoch 0) acc: 0.7303333333333333; ap: 0.7909018270339996; TPR: 0.6472131147540984; TNR: 0.816271186440678\n",
      "Validation accuracy increased (-inf --> 0.730333).  Saving model ...\n",
      "Train loss: 0.5829679369926453 at step: 700\n",
      "Train loss: 0.6199861168861389 at step: 800\n",
      "Train loss: 0.3708970546722412 at step: 900\n",
      "Train loss: 0.375710129737854 at step: 1000\n",
      "Train loss: 0.4385966360569 at step: 1100\n",
      "Train loss: 0.38256895542144775 at step: 1200\n",
      "(Val @ epoch 1) acc: 0.704; ap: 0.7985546503103771; TPR: 0.9085487077534792; TNR: 0.4969818913480885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.37851256132125854 at step: 1300\n",
      "Train loss: 0.42728373408317566 at step: 1400\n",
      "Train loss: 0.5170038342475891 at step: 1500\n",
      "Train loss: 0.4796614646911621 at step: 1600\n",
      "Train loss: 0.43811362981796265 at step: 1700\n",
      "Train loss: 0.4688934087753296 at step: 1800\n",
      "(Val @ epoch 2) acc: 0.7756666666666666; ap: 0.8319537808969406; TPR: 0.8774410774410775; TNR: 0.6759075907590759\n",
      "Validation accuracy increased (0.730333 --> 0.775667).  Saving model ...\n",
      "Train loss: 0.21624664962291718 at step: 1900\n",
      "Train loss: 0.37373682856559753 at step: 2000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 3, model.total_steps 2000)\n",
      "Train loss: 0.45699554681777954 at step: 2100\n",
      "Train loss: 0.30479466915130615 at step: 2200\n",
      "Train loss: 0.4257727265357971 at step: 2300\n",
      "Train loss: 0.40030211210250854 at step: 2400\n",
      "Train loss: 0.42673569917678833 at step: 2500\n",
      "(Val @ epoch 3) acc: 0.783; ap: 0.8711640559527127; TPR: 0.8211702827087443; TNR: 0.7437457741717377\n",
      "Validation accuracy increased (0.775667 --> 0.783000).  Saving model ...\n",
      "Train loss: 0.3583272695541382 at step: 2600\n",
      "Train loss: 0.5332660675048828 at step: 2700\n",
      "Train loss: 0.3647053837776184 at step: 2800\n",
      "Train loss: 0.5259919166564941 at step: 2900\n",
      "Train loss: 0.39552757143974304 at step: 3000\n",
      "Train loss: 0.4144439101219177 at step: 3100\n",
      "(Val @ epoch 4) acc: 0.7746666666666666; ap: 0.8605810597006714; TPR: 0.9279891304347826; TNR: 0.6269633507853403\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.4306807219982147 at step: 3200\n",
      "Train loss: 0.35640519857406616 at step: 3300\n",
      "Train loss: 0.3026069402694702 at step: 3400\n",
      "Train loss: 0.31337815523147583 at step: 3500\n",
      "Train loss: 0.5049046874046326 at step: 3600\n",
      "Train loss: 0.4422690272331238 at step: 3700\n",
      "saving the model at the end of epoch 5, iters 3750\n",
      "(Val @ epoch 5) acc: 0.7663333333333333; ap: 0.841752377810233; TPR: 0.8005164622336992; TNR: 0.729841488628532\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.6345546245574951 at step: 3800\n",
      "Train loss: 0.47735998034477234 at step: 3900\n",
      "Train loss: 0.3975142538547516 at step: 4000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 6, model.total_steps 4000)\n",
      "Train loss: 0.33545079827308655 at step: 4100\n",
      "Train loss: 0.37947791814804077 at step: 4200\n",
      "Train loss: 0.387763649225235 at step: 4300\n",
      "(Val @ epoch 6) acc: 0.799; ap: 0.8874445967530566; TPR: 0.9404517453798767; TNR: 0.6647173489278753\n",
      "Validation accuracy increased (0.783000 --> 0.799000).  Saving model ...\n",
      "Train loss: 0.22268599271774292 at step: 4400\n",
      "Train loss: 0.3692123591899872 at step: 4500\n",
      "Train loss: 0.32829728722572327 at step: 4600\n",
      "Train loss: 0.43992388248443604 at step: 4700\n",
      "Train loss: 0.39947783946990967 at step: 4800\n",
      "Train loss: 0.338300883769989 at step: 4900\n",
      "Train loss: 0.32038214802742004 at step: 5000\n",
      "(Val @ epoch 7) acc: 0.7853333333333333; ap: 0.8769880630754416; TPR: 0.9254032258064516; TNR: 0.6474867724867724\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.3019286096096039 at step: 5100\n",
      "Train loss: 0.3268810510635376 at step: 5200\n",
      "Train loss: 0.2819594144821167 at step: 5300\n",
      "Train loss: 0.4133710563182831 at step: 5400\n",
      "Train loss: 0.43962597846984863 at step: 5500\n",
      "Train loss: 0.4041155278682709 at step: 5600\n",
      "(Val @ epoch 8) acc: 0.8176666666666667; ap: 0.9038517755797512; TPR: 0.920911528150134; TNR: 0.7155172413793104\n",
      "Validation accuracy increased (0.799000 --> 0.817667).  Saving model ...\n",
      "Train loss: 0.28970515727996826 at step: 5700\n",
      "Train loss: 0.5697836875915527 at step: 5800\n",
      "Train loss: 0.38362306356430054 at step: 5900\n",
      "Train loss: 0.3684881925582886 at step: 6000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 9, model.total_steps 6000)\n",
      "Train loss: 0.598172128200531 at step: 6100\n",
      "Train loss: 0.39388763904571533 at step: 6200\n",
      "(Val @ epoch 9) acc: 0.8076666666666666; ap: 0.9032383131856193; TPR: 0.929144385026738; TNR: 0.6868351063829787\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.4040288031101227 at step: 6300\n",
      "Train loss: 0.2079538255929947 at step: 6400\n",
      "Train loss: 0.24286116659641266 at step: 6500\n",
      "Train loss: 0.3427685499191284 at step: 6600\n",
      "Train loss: 0.40971648693084717 at step: 6700\n",
      "Train loss: 0.43309953808784485 at step: 6800\n",
      "saving the model at the end of epoch 10, iters 6875\n",
      "(Val @ epoch 10) acc: 0.808; ap: 0.8869216690754868; TPR: 0.9274469541409993; TNR: 0.6946068875893437\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.39821603894233704 at step: 6900\n",
      "Train loss: 0.45160844922065735 at step: 7000\n",
      "Train loss: 0.3342037796974182 at step: 7100\n",
      "Train loss: 0.4887436628341675 at step: 7200\n",
      "Train loss: 0.289747029542923 at step: 7300\n",
      "Train loss: 0.242977574467659 at step: 7400\n",
      "Train loss: 0.38360753655433655 at step: 7500\n",
      "(Val @ epoch 11) acc: 0.7976666666666666; ap: 0.892124372853411; TPR: 0.890330953926022; TNR: 0.6997943797121315\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.47437286376953125 at step: 7600\n",
      "Train loss: 0.4195895195007324 at step: 7700\n",
      "Train loss: 0.3762398660182953 at step: 7800\n",
      "Train loss: 0.40137356519699097 at step: 7900\n",
      "Train loss: 0.2856422960758209 at step: 8000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 12, model.total_steps 8000)\n",
      "Train loss: 0.3699755072593689 at step: 8100\n",
      "(Val @ epoch 12) acc: 0.7863333333333333; ap: 0.8988779178793643; TPR: 0.932145305003427; TNR: 0.6482803374432187\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Train loss: 0.5060771703720093 at step: 8200\n",
      "Train loss: 0.5436831712722778 at step: 8300\n",
      "Train loss: 0.3434440493583679 at step: 8400\n",
      "Train loss: 0.3328009247779846 at step: 8500\n",
      "Train loss: 0.2855982780456543 at step: 8600\n",
      "Train loss: 0.5024634003639221 at step: 8700\n",
      "(Val @ epoch 13) acc: 0.8153333333333334; ap: 0.9130515581549286; TPR: 0.9240340537000655; TNR: 0.7026476578411406\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Learning rate dropped by 10, continue training...\n",
      "Train loss: 0.27918314933776855 at step: 8800\n",
      "Train loss: 0.38480520248413086 at step: 8900\n",
      "Train loss: 0.3481695055961609 at step: 9000\n",
      "Train loss: 0.23344215750694275 at step: 9100\n",
      "Train loss: 0.3833116888999939 at step: 9200\n",
      "Train loss: 0.33416691422462463 at step: 9300\n",
      "(Val @ epoch 14) acc: 0.828; ap: 0.9177438831376317; TPR: 0.9328813559322033; TNR: 0.7265573770491803\n",
      "Validation accuracy increased (-inf --> 0.828000).  Saving model ...\n",
      "Train loss: 0.3418392539024353 at step: 9400\n",
      "Train loss: 0.3716798424720764 at step: 9500\n",
      "Train loss: 0.22260306775569916 at step: 9600\n",
      "Train loss: 0.3344336748123169 at step: 9700\n",
      "Train loss: 0.45718955993652344 at step: 9800\n",
      "Train loss: 0.36670982837677 at step: 9900\n",
      "Train loss: 0.33434420824050903 at step: 10000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 15, model.total_steps 10000)\n",
      "saving the model at the end of epoch 15, iters 10000\n",
      "(Val @ epoch 15) acc: 0.8316666666666667; ap: 0.9236086959891875; TPR: 0.9342915811088296; TNR: 0.7342430149447693\n",
      "Validation accuracy increased (0.828000 --> 0.831667).  Saving model ...\n",
      "Train loss: 0.19503885507583618 at step: 10100\n",
      "Train loss: 0.2988053560256958 at step: 10200\n",
      "Train loss: 0.3732209801673889 at step: 10300\n",
      "Train loss: 0.44481509923934937 at step: 10400\n",
      "Train loss: 0.40020883083343506 at step: 10500\n",
      "Train loss: 0.45658957958221436 at step: 10600\n",
      "(Val @ epoch 16) acc: 0.8323333333333334; ap: 0.9314618808280035; TPR: 0.9555555555555556; TNR: 0.7115511551155116\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.38703620433807373 at step: 10700\n",
      "Train loss: 0.3289872407913208 at step: 10800\n",
      "Train loss: 0.2669713497161865 at step: 10900\n",
      "Train loss: 0.4153553545475006 at step: 11000\n",
      "Train loss: 0.34121835231781006 at step: 11100\n",
      "Train loss: 0.27488118410110474 at step: 11200\n",
      "(Val @ epoch 17) acc: 0.848; ap: 0.9392210374136728; TPR: 0.9351316634553629; TNR: 0.753984753984754\n",
      "Validation accuracy increased (0.831667 --> 0.848000).  Saving model ...\n",
      "Train loss: 0.40396592020988464 at step: 11300\n",
      "Train loss: 0.4327849745750427 at step: 11400\n",
      "Train loss: 0.27875030040740967 at step: 11500\n",
      "Train loss: 0.2031283676624298 at step: 11600\n",
      "Train loss: 0.33619049191474915 at step: 11700\n",
      "Train loss: 0.1652066707611084 at step: 11800\n",
      "(Val @ epoch 18) acc: 0.8413333333333334; ap: 0.9390961542337732; TPR: 0.9428950863213812; TNR: 0.7389558232931727\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.467027485370636 at step: 11900\n",
      "Train loss: 0.4556652903556824 at step: 12000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 19, model.total_steps 12000)\n",
      "Train loss: 0.31115981936454773 at step: 12100\n",
      "Train loss: 0.1595200151205063 at step: 12200\n",
      "Train loss: 0.3822300434112549 at step: 12300\n",
      "Train loss: 0.27238911390304565 at step: 12400\n",
      "Train loss: 0.2831110954284668 at step: 12500\n",
      "(Val @ epoch 19) acc: 0.8493333333333334; ap: 0.9391650736339148; TPR: 0.9435757987763427; TNR: 0.7586657946370177\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.23658594489097595 at step: 12600\n",
      "Train loss: 0.4906637668609619 at step: 12700\n",
      "Train loss: 0.18451040983200073 at step: 12800\n",
      "Train loss: 0.2953270971775055 at step: 12900\n",
      "Train loss: 0.39330556988716125 at step: 13000\n",
      "Train loss: 0.25584712624549866 at step: 13100\n",
      "saving the model at the end of epoch 20, iters 13125\n",
      "(Val @ epoch 20) acc: 0.84; ap: 0.9323378487716483; TPR: 0.9296977660972404; TNR: 0.7476319350473613\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.27306294441223145 at step: 13200\n",
      "Train loss: 0.3029545843601227 at step: 13300\n",
      "Train loss: 0.3118610978126526 at step: 13400\n",
      "Train loss: 0.2175104171037674 at step: 13500\n",
      "Train loss: 0.2611654996871948 at step: 13600\n",
      "Train loss: 0.377626895904541 at step: 13700\n",
      "(Val @ epoch 21) acc: 0.8483333333333334; ap: 0.9346491289543736; TPR: 0.9251336898395722; TNR: 0.7719414893617021\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Train loss: 0.18742981553077698 at step: 13800\n",
      "Train loss: 0.40423715114593506 at step: 13900\n",
      "Train loss: 0.3414839804172516 at step: 14000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 22, model.total_steps 14000)\n",
      "Train loss: 0.30207765102386475 at step: 14100\n",
      "Train loss: 0.24568651616573334 at step: 14200\n",
      "Train loss: 0.27689942717552185 at step: 14300\n",
      "(Val @ epoch 22) acc: 0.8476666666666667; ap: 0.9327836210244993; TPR: 0.9276315789473685; TNR: 0.7655405405405405\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Learning rate dropped by 10, continue training...\n",
      "Train loss: 0.3295145034790039 at step: 14400\n",
      "Train loss: 0.19221362471580505 at step: 14500\n",
      "Train loss: 0.3709331750869751 at step: 14600\n",
      "Train loss: 0.3900793790817261 at step: 14700\n",
      "Train loss: 0.46342000365257263 at step: 14800\n",
      "Train loss: 0.4573332965373993 at step: 14900\n",
      "Train loss: 0.31267085671424866 at step: 15000\n",
      "(Val @ epoch 23) acc: 0.8443333333333334; ap: 0.9352354244380263; TPR: 0.9387222946544981; TNR: 0.7455661664392906\n",
      "Validation accuracy increased (-inf --> 0.844333).  Saving model ...\n",
      "Train loss: 0.3180704116821289 at step: 15100\n",
      "Train loss: 0.2794100046157837 at step: 15200\n",
      "Train loss: 0.23473840951919556 at step: 15300\n",
      "Train loss: 0.21481162309646606 at step: 15400\n",
      "Train loss: 0.3205299973487854 at step: 15500\n",
      "Train loss: 0.3298174738883972 at step: 15600\n",
      "(Val @ epoch 24) acc: 0.8376666666666667; ap: 0.9415063752950804; TPR: 0.9462999345121152; TNR: 0.725050916496945\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.28318697214126587 at step: 15700\n",
      "Train loss: 0.3786752223968506 at step: 15800\n",
      "Train loss: 0.3135274052619934 at step: 15900\n",
      "Train loss: 0.29078179597854614 at step: 16000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 25, model.total_steps 16000)\n",
      "Train loss: 0.16747218370437622 at step: 16100\n",
      "Train loss: 0.3106490969657898 at step: 16200\n",
      "saving the model at the end of epoch 25, iters 16250\n",
      "(Val @ epoch 25) acc: 0.8523333333333334; ap: 0.9427133579148058; TPR: 0.9275653923541247; TNR: 0.777998674618953\n",
      "Validation accuracy increased (0.844333 --> 0.852333).  Saving model ...\n",
      "Train loss: 0.4173365831375122 at step: 16300\n",
      "Train loss: 0.30032479763031006 at step: 16400\n",
      "Train loss: 0.3330082297325134 at step: 16500\n",
      "Train loss: 0.3498181104660034 at step: 16600\n",
      "Train loss: 0.29465043544769287 at step: 16700\n",
      "Train loss: 0.11076083034276962 at step: 16800\n",
      "(Val @ epoch 26) acc: 0.8416666666666667; ap: 0.9263515227933141; TPR: 0.9331983805668016; TNR: 0.7523056653491436\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Train loss: 0.2540087401866913 at step: 16900\n",
      "Train loss: 0.38271868228912354 at step: 17000\n",
      "Train loss: 0.2649322748184204 at step: 17100\n",
      "Train loss: 0.343532532453537 at step: 17200\n",
      "Train loss: 0.19229620695114136 at step: 17300\n",
      "Train loss: 0.20049923658370972 at step: 17400\n",
      "Train loss: 0.3700028657913208 at step: 17500\n",
      "(Val @ epoch 27) acc: 0.8403333333333334; ap: 0.9429915927783179; TPR: 0.9387617765814267; TNR: 0.7437252311756936\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Train loss: 0.40744251012802124 at step: 17600\n",
      "Train loss: 0.24171864986419678 at step: 17700\n",
      "Train loss: 0.31169024109840393 at step: 17800\n",
      "Train loss: 0.3324123024940491 at step: 17900\n",
      "Train loss: 0.3244730234146118 at step: 18000\n",
      "saving the latest model 240508_CNNSpot_CAM (epoch 28, model.total_steps 18000)\n",
      "Train loss: 0.36857840418815613 at step: 18100\n",
      "(Val @ epoch 28) acc: 0.8486666666666667; ap: 0.9438778250440896; TPR: 0.9418449197860963; TNR: 0.7559840425531915\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Train loss: 0.3739773631095886 at step: 18200\n",
      "Train loss: 0.3392712473869324 at step: 18300\n",
      "Train loss: 0.49379730224609375 at step: 18400\n",
      "Train loss: 0.23836836218833923 at step: 18500\n",
      "Train loss: 0.24012218415737152 at step: 18600\n",
      "Train loss: 0.3057571053504944 at step: 18700\n",
      "batch number 26/94\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--name 240508_CNNSpot_CAM \\\n",
    "--niter 1000 \\\n",
    "--batch_size 32 \\\n",
    "--dataroot /workspace/AIGCDetectBenchmark_ver2/dataset/RealFakeDB512s \\\n",
    "--model_path_trained /workspace/AIGCDetectBenchmark_ver2/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth \\\n",
    "--detect_method CNNSpot_CAM \\\n",
    "--blur_prob 0.1 --blur_sig 0.0,3.0 --jpg_prob 0.1 --jpg_method cv2,pil --jpg_qual 30,100 \\\n",
    "--num_threads 4 \\\n",
    "--loss_freq 100 \\\n",
    "--comet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/240508_CNNSpot_CAM/model_epoch_best.pth\n",
      "checkpoints/240508_CNNSpot_CAM/model_epoch_latest.pth\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/*/*.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/real_gen_dataset\n",
      "----------------- Options ---------------\n",
      "    CNNSpot_CAM_inference: True                          \t[default: False]\n",
      "                 CropSize: 224                           \n",
      "           DIRE_modelpath: ./weights/preprocessing/lsun_bedroom.pt\n",
      "          LGrad_modelpath: ./weights/preprocessing/karras2019stylegan-bedrooms-256x256_discriminator.pth\n",
      "            LNP_modelpath: ./weights/preprocessing/sidd_rgb.pth\n",
      "               batch_size: 1                             \t[default: 64]\n",
      "                 blur_sig: 1.0                           \n",
      "                    comet: False                         \n",
      "                dataroot2: None                          \n",
      "            detect_method: CNNSpot_CAM                   \t[default: CNNSpot]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                    isVal: False                         \t[default: None]\n",
      "               jpg_method: pil                           \n",
      "                 jpg_qual: 95                            \n",
      "                 loadSize: 256                           \n",
      "           method_combine: None                          \n",
      "               model_path: /workspace/AIGCDetectBenchmark_ver2_old1/checkpoints/240508_CNNSpot_CAM/model_epoch_best.pth\t[default: ./weights/classifier/CNNSpot.pth]\n",
      "       model_path_trained: /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth\t[default: ./weights/classifier/CNNSpot.pth]\n",
      "                  no_crop: False                         \n",
      "                  no_flip: False                         \n",
      "                no_resize: False                         \n",
      "               noise_type: None                          \n",
      "              num_threads: 4                             \n",
      "              results_dir: ./results/CNNSpot_CAM         \t[default: None]\n",
      "                rz_interp: bilinear                      \n",
      "----------------- End -------------------\n",
      "model_epoch_best model testing on...\n",
      "loading state_dict from:  /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth\n",
      "Evaluation: acc: 0.6964285714285714; ap: 0.6345288115246098; TPR: 0.7276785714285714; TNR: 0.6651785714285714\n"
     ]
    }
   ],
   "source": [
    "!python eval_all.py \\\n",
    "--detect_method CNNSpot_CAM \\\n",
    "--model_path /workspace/AIGCDetectBenchmark_ver2_old1/checkpoints/240508_CNNSpot_CAM/model_epoch_best.pth \\\n",
    "--model_path_trained /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth \\\n",
    "--CNNSpot_CAM_inference \\\n",
    "--num_threads 4 \\\n",
    "--batch_size 1 \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thres 0.1: acc: 0.6964285714285714; ap: 0.6345288115246098; TPR: 0.7276785714285714; TNR: 0.6651785714285714\n",
    "Thres 0.2: acc: 0.6908482142857143; ap: 0.6303652684307128; TPR: 0.7120535714285714; TNR: 0.6696428571428571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/real_gen_dataset\n",
      "----------------- Options ---------------\n",
      "    CNNSpot_CAM_inference: False                         \n",
      "                 CropSize: 224                           \n",
      "           DIRE_modelpath: ./weights/preprocessing/lsun_bedroom.pt\n",
      "          LGrad_modelpath: ./weights/preprocessing/karras2019stylegan-bedrooms-256x256_discriminator.pth\n",
      "            LNP_modelpath: ./weights/preprocessing/sidd_rgb.pth\n",
      "               batch_size: 1                             \t[default: 64]\n",
      "                 blur_sig: 1.0                           \n",
      "                    comet: False                         \n",
      "                dataroot2: None                          \n",
      "            detect_method: CNNSpot                       \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                    isVal: False                         \t[default: None]\n",
      "               jpg_method: pil                           \n",
      "                 jpg_qual: 95                            \n",
      "                 loadSize: 256                           \n",
      "           method_combine: None                          \n",
      "               model_path: /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth\t[default: ./weights/classifier/CNNSpot.pth]\n",
      "       model_path_trained: /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth\t[default: ./weights/classifier/CNNSpot.pth]\n",
      "                  no_crop: False                         \n",
      "                  no_flip: False                         \n",
      "                no_resize: False                         \n",
      "               noise_type: None                          \n",
      "              num_threads: 4                             \n",
      "              results_dir: ./results/CNNSpot             \t[default: None]\n",
      "                rz_interp: bilinear                      \n",
      "----------------- End -------------------\n",
      "CNNSpot_1isreal_model_epoch_best model testing on...\n",
      "Evaluation: acc: 0.6227678571428571; ap: 0.7050296833373686; TPR: 0.9352678571428571; TNR: 0.31026785714285715\n"
     ]
    }
   ],
   "source": [
    "#!python eval_all.py \\\n",
    "--detect_method CNNSpot \\\n",
    "--model_path /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth \\\n",
    "--model_path_trained /workspace/AIGCDetectBenchmark_ver2_old1/weights/classifier/CNNSpot_1isreal_model_epoch_best.pth \\\n",
    "--num_threads 4 \\\n",
    "--batch_size 1 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-WXaGdEcrbD"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/WEIGHTS/240427_FreDect_checkpoint.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9g2F58gSiW4"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/DATASETS/Common/real_gen_dataset.zip -d data/real_gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjDP2YEYStJ-"
   },
   "outputs": [],
   "source": [
    "!cp /content/AIGCDetectBenchmark/checkpoints/FreDect/model_epoch_best.pth -d /content/drive/MyDrive/WEIGHTS/FreDect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /workspace/real_gen_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/240508_CNNSpot_CAM/model_epoch_best.pth\n",
      "checkpoints/240508_CNNSpot_CAM/model_epoch_latest.pth\n",
      "checkpoints/240508_CNNSpot_CAM/opt.txt\n",
      "\n",
      "checkpoints/240508_CNNSpot_CAM/train:\n",
      "events.out.tfevents.1715173749.98946ed5acdd\n",
      "events.out.tfevents.1715174031.98946ed5acdd\n",
      "events.out.tfevents.1715174510.98946ed5acdd\n",
      "events.out.tfevents.1715174913.98946ed5acdd\n",
      "events.out.tfevents.1715175050.98946ed5acdd\n",
      "events.out.tfevents.1715175134.98946ed5acdd\n",
      "events.out.tfevents.1715175275.98946ed5acdd\n",
      "events.out.tfevents.1715175316.98946ed5acdd\n",
      "events.out.tfevents.1715175371.98946ed5acdd\n",
      "events.out.tfevents.1715177383.98946ed5acdd\n",
      "events.out.tfevents.1715177550.98946ed5acdd\n",
      "events.out.tfevents.1715178966.98946ed5acdd\n",
      "events.out.tfevents.1715179191.98946ed5acdd\n",
      "events.out.tfevents.1715180786.98946ed5acdd\n",
      "events.out.tfevents.1715180910.98946ed5acdd\n",
      "events.out.tfevents.1715181825.98946ed5acdd\n",
      "events.out.tfevents.1715182360.98946ed5acdd\n",
      "\n",
      "checkpoints/240508_CNNSpot_CAM/val:\n",
      "events.out.tfevents.1715173749.98946ed5acdd\n",
      "events.out.tfevents.1715174031.98946ed5acdd\n",
      "events.out.tfevents.1715174510.98946ed5acdd\n",
      "events.out.tfevents.1715174913.98946ed5acdd\n",
      "events.out.tfevents.1715175050.98946ed5acdd\n",
      "events.out.tfevents.1715175134.98946ed5acdd\n",
      "events.out.tfevents.1715175275.98946ed5acdd\n",
      "events.out.tfevents.1715175316.98946ed5acdd\n",
      "events.out.tfevents.1715175371.98946ed5acdd\n",
      "events.out.tfevents.1715177383.98946ed5acdd\n",
      "events.out.tfevents.1715177550.98946ed5acdd\n",
      "events.out.tfevents.1715178966.98946ed5acdd\n",
      "events.out.tfevents.1715179191.98946ed5acdd\n",
      "events.out.tfevents.1715180786.98946ed5acdd\n",
      "events.out.tfevents.1715180910.98946ed5acdd\n",
      "events.out.tfevents.1715181825.98946ed5acdd\n",
      "events.out.tfevents.1715182360.98946ed5acdd\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/*/*\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709M\tcheckpoints/240508_CNNSpot_CAM/model_epoch_best.pth\n",
      "709M\tcheckpoints/240508_CNNSpot_CAM/model_epoch_latest.pth\n",
      "4.0K\tcheckpoints/240508_CNNSpot_CAM/opt.txt\n",
      "76K\tcheckpoints/240508_CNNSpot_CAM/train\n",
      "68K\tcheckpoints/240508_CNNSpot_CAM/val\n"
     ]
    }
   ],
   "source": [
    "!du -h checkpoints/240508_CNNSpot_CAM/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/AIGCDetectBenchmark_ver2/checkpoints\n"
     ]
    }
   ],
   "source": [
    "%cd checkpoints\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: 240508_CNNSpot_CAM/ (stored 0%)\n",
      "  adding: 240508_CNNSpot_CAM/opt.txt (deflated 74%)\n",
      "  adding: 240508_CNNSpot_CAM/train/ (stored 0%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715173749.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715174031.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715174510.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715174913.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715175050.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715175134.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715175275.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715175316.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715175371.98946ed5acdd (deflated 30%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715177383.98946ed5acdd (stored 0%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715177550.98946ed5acdd (deflated 31%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715178966.98946ed5acdd (deflated 33%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715179191.98946ed5acdd (deflated 48%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715180786.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715180910.98946ed5acdd (deflated 47%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715181825.98946ed5acdd (deflated 38%)\n",
      "  adding: 240508_CNNSpot_CAM/train/events.out.tfevents.1715182360.98946ed5acdd (deflated 58%)\n",
      "  adding: 240508_CNNSpot_CAM/val/ (stored 0%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715173749.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715174031.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715174510.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715174913.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715175050.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715175134.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715175275.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715175316.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715175371.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715177383.98946ed5acdd (stored 0%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715177550.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715178966.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715179191.98946ed5acdd (deflated 46%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715180786.98946ed5acdd (deflated 5%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715180910.98946ed5acdd (deflated 50%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715181825.98946ed5acdd (deflated 16%)\n",
      "  adding: 240508_CNNSpot_CAM/val/events.out.tfevents.1715182360.98946ed5acdd (deflated 58%)\n",
      "  adding: 240508_CNNSpot_CAM/model_epoch_latest.pth (deflated 10%)\n",
      "  adding: 240508_CNNSpot_CAM/model_epoch_best.pth (deflated 10%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r 240508_CNNSpot_CAM.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r checkpoints/240508_CNNSpot_CAM/model_epoch_0.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv 240508_CNNSpot_CAM.zip /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /workspace/RealFakeDB512s.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
